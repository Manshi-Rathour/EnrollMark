{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fdda3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mansh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import pathlib\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import pymysql\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1afba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"..\\\\student_images\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57829760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../student_images')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = pathlib.Path(data_path)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ca690c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../student_images/Ananya Rathour/IMG_20240317_143108.jpg')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(path.glob('*/*.jpg'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7163682e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "image_count = len(list(path.glob('*/*.jpg')))\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73121c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../student_images/Ananya Rathour/IMG_20240317_143108.jpg'),\n",
       " WindowsPath('../student_images/Ananya Rathour/IMG_20240317_143111.jpg'),\n",
       " WindowsPath('../student_images/Ananya Rathour/IMG_20240317_143114.jpg'),\n",
       " WindowsPath('../student_images/Ananya Rathour/IMG_20240317_143119.jpg'),\n",
       " WindowsPath('../student_images/Ananya Rathour/IMG_20240317_143122.jpg')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = list(path.glob('Ananya Rathour/*'))\n",
    "img[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51754fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PIL.Image.open(str(img[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b862158",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_images_dict = {\n",
    "    'Ananya Rathour': list(path.glob('Ananya Rathour/*')),\n",
    "    'Manshi Rathour': list(path.glob('Manshi Rathour/*')),\n",
    "    'Naincy Rathour': list(path.glob('Naincy Rathour/*')),\n",
    "    'Mayank Rathour': list(path.glob('Mayank Rathour/*'))    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8601ddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(str(student_images_dict['Ananya Rathour'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34d716f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1909, 1432, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf08a20",
   "metadata": {},
   "source": [
    "## Saving image of new student in new folder and also appending its path in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e502dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images_for_new_student(new_student_name, image_data, data_path):\n",
    "    # Create a folder for the new student if it doesn't exist\n",
    "    student_folder_path = os.path.join(data_path, new_student_name)\n",
    "    os.makedirs(student_folder_path, exist_ok=True)\n",
    "    \n",
    "    # Save the images sent from the backend\n",
    "    image_paths = []\n",
    "    for i, image in enumerate(image_data):\n",
    "        image_path = os.path.join(student_folder_path, f\"image_{i+1}.jpg\")\n",
    "        with open(image_path, \"wb\") as file:\n",
    "            file.write(image)\n",
    "        image_paths.append(pathlib.Path(image_path))\n",
    "    \n",
    "    # Update student_images_dict with the new student folder path\n",
    "    student_images_dict[new_student_name] = image_paths\n",
    "    \n",
    "    return student_images_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33798d58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# new_student_name = \"New Student\"\n",
    "# image_data = [b'image_1_data', b'image_2_data', b'image_3_data', b'image_4_data', b'image_5_data', b'image_6_data']\n",
    "# save_images_for_new_student(new_student_name, image_data, data_path)\n",
    "# student_images_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3152bb76",
   "metadata": {},
   "source": [
    "## Connecting to MySQL server to fetch student name with their details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97dd2de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Dictionary:\n",
      "{'Manshi Rathour': 1, 'Ananya Rathour': 2, 'Naincy Rathour': 3, 'Mayank Rathour': 4}\n"
     ]
    }
   ],
   "source": [
    "def load_data_from_mysql(host, user, password, database, student_images_dict):\n",
    "    try:\n",
    "        # Connect to MySQL without specifying the authentication plugin\n",
    "        connection = pymysql.connect(\n",
    "            host=host,\n",
    "            user=user,\n",
    "            password=password,\n",
    "            database=database\n",
    "        )\n",
    "\n",
    "        # Create a cursor object\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Execute a query to fetch data\n",
    "        query = \"SELECT * FROM students\"\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Fetch data and convert it into a DataFrame\n",
    "        data = cursor.fetchall()\n",
    "        df = pd.DataFrame(data, columns=[col[0] for col in cursor.description])\n",
    "\n",
    "        # Convert DataFrame to dictionary\n",
    "        student_dict = df.set_index('name')['student_id'].to_dict()\n",
    "\n",
    "        # Close the cursor and connection\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "        return student_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    \n",
    "    \n",
    "host = 'localhost'\n",
    "user = 'root'\n",
    "password = 'root'\n",
    "database = 'smart_attendance'\n",
    "\n",
    "student_dict = load_data_from_mysql(host, user, password, database, student_images_dict)\n",
    "\n",
    "\n",
    "print(\"Student Dictionary:\")\n",
    "print(student_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e45891",
   "metadata": {},
   "source": [
    "## Resizing images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "000c43e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (38, 180, 180, 3)\n",
      "y shape: (38,)\n"
     ]
    }
   ],
   "source": [
    "def resize_images(student_images_dict, student_dict, X=None, y=None, image_size=(180, 180)):\n",
    "    if X is None:\n",
    "        X = []\n",
    "    if y is None:\n",
    "        y = []\n",
    "\n",
    "    processed_files = set()\n",
    "    \n",
    "    # Add existing files to processed_files\n",
    "    for img in X:\n",
    "        processed_files.add(img)\n",
    "    \n",
    "    for student_name, images in student_images_dict.items():\n",
    "        for image in images:\n",
    "            # Check if the image file exists\n",
    "            if os.path.exists(str(image)):\n",
    "                # Check if the image has been processed already\n",
    "                if str(image) not in processed_files:\n",
    "                    # Read the image\n",
    "                    img = cv2.imread(str(image))\n",
    "                    \n",
    "                    # Check if the image was read successfully\n",
    "                    if img is not None:\n",
    "                        # Resize the image\n",
    "                        resized_img = cv2.resize(img, image_size)\n",
    "                        \n",
    "                        # Convert BGR to RGB\n",
    "                        resized_img_rgb = cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                        # Append the resized image to X\n",
    "                        X.append(resized_img_rgb)\n",
    "                        \n",
    "                        # Append the corresponding label to y\n",
    "                        y.append(student_dict[student_name])\n",
    "                        \n",
    "                        # Add the filename to processed_files\n",
    "                        processed_files.add(str(image))\n",
    "                    else:\n",
    "                        print(f\"Unable to read image: {image}\")\n",
    "                else:\n",
    "                    print(f\"Image already processed: {image}\")\n",
    "            else:\n",
    "                print(f\"Image file does not exist: {image}\")\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = resize_images(student_images_dict, student_dict)\n",
    "\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0ee7e5",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d888b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625a548b",
   "metadata": {},
   "source": [
    "## Processing : scale images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04d1fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train / 255\n",
    "X_test_scaled = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136e8b9b",
   "metadata": {},
   "source": [
    "# Build convolutional neural network and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4288a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mansh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "                                                 input_shape=(180, \n",
    "                                                              180,\n",
    "                                                              3)),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3a71489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mansh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mansh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:From C:\\Users\\mansh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mansh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.4892 - accuracy: 0.2500\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 4.3532 - accuracy: 0.2857\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 7.2397 - accuracy: 0.2857\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 4.9593 - accuracy: 0.2500\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 2.8362 - accuracy: 0.2500\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 1.5119 - accuracy: 0.5357\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 1.1736 - accuracy: 0.4643\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 174ms/step - loss: 1.0441 - accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.9277 - accuracy: 0.5714\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 0.8829 - accuracy: 0.5714\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.7676 - accuracy: 0.5714\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 171ms/step - loss: 0.6713 - accuracy: 0.8571\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 169ms/step - loss: 0.5882 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5145 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 0.4518 - accuracy: 0.9643\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3826 - accuracy: 0.9643\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.4058 - accuracy: 0.9286\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 0.3752 - accuracy: 0.8571\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.2418 - accuracy: 0.9643\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.1990 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.1654 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.1096 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.1306 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.0769 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0592 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 0.0477 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.0365 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.0175 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x281f0efb650>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 5\n",
    "\n",
    "model = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "model.fit(X_train_scaled, y_train, epochs=30)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e38dc4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 227ms/step - loss: 0.4399 - accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4398633539676666, 0.8999999761581421]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e1402fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 134ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-10.613449  ,   2.1189766 ,  -0.53918976,   5.1935725 ,\n",
       "          1.2792971 ],\n",
       "       [-11.619715  ,   0.27666864,   5.519066  ,   1.5247225 ,\n",
       "          3.8101747 ],\n",
       "       [-13.396381  ,   8.917156  ,  -4.603524  ,   2.1131668 ,\n",
       "          2.4409087 ],\n",
       "       [-12.786484  ,   8.450519  ,  -3.9634898 ,   1.8976936 ,\n",
       "          2.304776  ],\n",
       "       [-12.2775955 ,   7.233598  ,  -3.2393267 ,   1.5744544 ,\n",
       "          2.7039654 ],\n",
       "       [-13.351382  ,   9.072342  ,  -4.213699  ,   2.3564663 ,\n",
       "          1.9061737 ],\n",
       "       [-10.416382  ,   2.2982593 ,  -0.89488137,   5.1814146 ,\n",
       "          1.369103  ],\n",
       "       [-12.613455  ,   7.1322713 ,  -3.2532377 ,   2.1346457 ,\n",
       "          2.604177  ],\n",
       "       [-10.27751   ,   1.9655902 ,   0.11039606,   5.6852584 ,\n",
       "          0.62262446],\n",
       "       [-10.940866  ,  -7.660872  ,  23.431868  ,   4.7805014 ,\n",
       "         -3.0649114 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test_scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83fa4a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tf.nn.softmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfe53175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb2ed265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a74e5",
   "metadata": {},
   "source": [
    "## Save trained model to pickel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c417ac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
